#!/usr/bin/env python
# -*- coding: utf-8 -*-
import json
import os

# Change to working directory
os.chdir(r'c:\Users\Mostafa\OneDrive\Attachments\MY work')

# Read all words from the bulk files
with open('_bulk_a1.txt', 'r', encoding='utf-8') as f:
    a1_words = [w.strip() for w in f.read().split(',') if w.strip()]
with open('_bulk_a2.txt', 'r', encoding='utf-8') as f:
    a2_words = [w.strip() for w in f.read().split(',') if w.strip()]
with open('_bulk_b1.txt', 'r', encoding='utf-8') as f:
    b1_words = [w.strip() for w in f.read().split(',') if w.strip()]
with open('_bulk_b2.txt', 'r', encoding='utf-8') as f:
    b2_words = [w.strip() for w in f.read().split(',') if w.strip()]

# Combine and deduplicate all words
all_words = set()
all_words.update(a1_words)
all_words.update(a2_words)
all_words.update(b1_words)
all_words.update(b2_words)

print(f"ğŸ“Š Total unique words collected: {len(all_words)}")
print(f"  â€¢ A1 words: {len(a1_words)}")
print(f"  â€¢ A2 words: {len(a2_words)}")
print(f"  â€¢ B1 words: {len(b1_words)}")
print(f"  â€¢ B2 words: {len(b2_words)}")

# Arabic translations dictionary (core vocabulary)
arabic_trans = {
    'a': 'Ø§', 'able': 'Ù‚Ø§Ø¯Ø±', 'about': 'Ø­ÙˆÙ„', 'acid': 'Ø­Ù…Ø¶ÙŠ', 'act': 'ÙØ¹Ù„', 'add': 'Ø¥Ø¶Ø§ÙØ©',
    'age': 'Ø¹Ù…Ø±', 'ago': 'Ù…Ù†Ø°', 'aid': 'Ù…Ø³Ø§Ø¹Ø¯Ø©', 'aim': 'Ù‡Ø¯Ù', 'air': 'Ù‡ÙˆØ§Ø¡', 'all': 'Ø§Ù„Ø¬Ù…ÙŠØ¹',
    'animal': 'Ø­ÙŠÙˆØ§Ù†', 'any': 'Ø£ÙŠ', 'area': 'Ù…Ù†Ø·Ù‚Ø©', 'arm': 'Ø°Ø±Ø§Ø¹', 'army': 'Ø¬ÙŠØ´', 'art': 'ÙÙ†',
    'ask': 'Ø³Ø¤Ø§Ù„', 'at': 'ÙÙŠ', 'away': 'Ø¨Ø¹ÙŠØ¯Ø§', 'baby': 'Ø±Ø¶ÙŠØ¹', 'back': 'Ø®Ù„Ù', 'bad': 'Ø³ÙŠØ¡',
    'bag': 'Ø­Ù‚ÙŠØ¨Ø©', 'ball': 'ÙƒØ±Ø©', 'bank': 'Ø¨Ù†Ùƒ', 'bar': 'Ø­Ø§Ù†Ø©', 'base': 'Ù‚Ø§Ø¹Ø¯Ø©', 'be': 'ÙŠÙƒÙˆÙ†',
    'beach': 'Ø´Ø§Ø·Ø¦', 'bear': 'Ø¯Ø¨', 'bed': 'Ø³Ø±ÙŠØ±', 'begin': 'Ø¨Ø¯Ø§ÙŠØ©', 'bell': 'Ø¬Ø±Ø³',
    'best': 'Ø£ÙØ¶Ù„', 'big': 'ÙƒØ¨ÙŠØ±', 'bike': 'Ø¯Ø±Ø§Ø¬Ø©', 'bird': 'Ø·Ø§Ø¦Ø±', 'black': 'Ø£Ø³ÙˆØ¯',
    'blood': 'Ø¯Ù…', 'blue': 'Ø£Ø²Ø±Ù‚', 'boat': 'Ù‚Ø§Ø±Ø¨', 'body': 'Ø¬Ø³Ù…', 'book': 'ÙƒØªØ§Ø¨',
    'born': 'Ù…ÙˆÙ„ÙˆØ¯', 'boss': 'Ø±Ø¦ÙŠØ³', 'both': 'ÙƒÙ„Ø§Ù‡Ù…Ø§', 'box': 'ØµÙ†Ø¯ÙˆÙ‚', 'boy': 'ÙˆÙ„Ø¯',
    'brain': 'Ø¯Ù…Ø§Øº', 'bread': 'Ø®Ø¨Ø²', 'breath': 'ØªÙ†ÙØ³', 'brother': 'Ø£Ø®', 'brown': 'Ø¨Ù†ÙŠ',
    'build': 'Ø¨Ù†Ø§Ø¡', 'burn': 'Ø§Ø­ØªØ±Ø§Ù‚', 'bus': 'Ø­Ø§ÙÙ„Ø©', 'business': 'Ø¹Ù…Ù„', 'but': 'Ù„ÙƒÙ†',
    'buy': 'Ø´Ø±Ø§Ø¡', 'by': 'Ø¨ÙˆØ§Ø³Ø·Ø©', 'call': 'Ø§Ø³ØªØ¯Ø¹Ø§Ø¡', 'can': 'ÙŠÙ…ÙƒÙ†', 'car': 'Ø³ÙŠØ§Ø±Ø©',
    'card': 'Ø¨Ø·Ø§Ù‚Ø©', 'care': 'Ø±Ø¹Ø§ÙŠØ©', 'case': 'Ø­Ø§Ù„Ø©', 'cat': 'Ù‚Ø·Ø©', 'cause': 'Ø³Ø¨Ø¨',
    'cell': 'Ø®Ù„ÙŠØ©', 'center': 'Ù…Ø±ÙƒØ²', 'century': 'Ù‚Ø±Ù†', 'certain': 'Ù…Ø¤ÙƒØ¯', 'chair': 'ÙƒØ±Ø³ÙŠ',
    'change': 'ØªØºÙŠÙŠØ±', 'character': 'Ø´Ø®ØµÙŠØ©', 'cheap': 'Ø±Ø®ÙŠØµ', 'check': 'ÙØ­Øµ', 'cheese': 'Ø¬Ø¨Ù†',
    'chef': 'Ø·Ø§Ù‡', 'chest': 'ØµØ¯Ø±', 'chicken': 'Ø¯Ø¬Ø§Ø¬', 'chief': 'Ø±Ø¦ÙŠØ³', 'child': 'Ø·ÙÙ„',
    'choice': 'Ø§Ø®ØªÙŠØ§Ø±', 'choose': 'Ø§Ø®ØªÙŠØ§Ø±', 'church': 'ÙƒÙ†ÙŠØ³Ø©', 'city': 'Ù…Ø¯ÙŠÙ†Ø©', 'class': 'ÙØ¦Ø©',
    'clean': 'Ù†Ø¸ÙŠÙ', 'clear': 'ÙˆØ§Ø¶Ø­', 'climb': 'ØªØ³Ù„Ù‚', 'clock': 'Ø³Ø§Ø¹Ø©', 'close': 'Ù‚Ø±ÙŠØ¨',
    'cloud': 'Ø³Ø­Ø§Ø¨Ø©', 'club': 'Ù†Ø§Ø¯ÙŠ', 'coach': 'Ù…Ø¯Ø±Ø¨', 'coast': 'Ø³Ø§Ø­Ù„', 'coat': 'Ù…Ø¹Ø·Ù',
    'code': 'Ø±Ù…Ø²', 'coffee': 'Ù‚Ù‡ÙˆØ©', 'cold': 'Ø¨Ø§Ø±Ø¯', 'color': 'Ù„ÙˆÙ†', 'come': 'Ù‚Ø¯ÙˆÙ…',
    'command': 'Ø£Ù…Ø±', 'comment': 'ØªØ¹Ù„ÙŠÙ‚', 'common': 'Ø´Ø§Ø¦Ø¹', 'company': 'Ø´Ø±ÙƒØ©', 'computer': 'ÙƒÙ…Ø¨ÙŠÙˆØªØ±',
    'concern': 'Ù‚Ù„Ù‚', 'condition': 'Ø´Ø±Ø·', 'conference': 'Ù…Ø¤ØªÙ…Ø±', 'confidence': 'Ø«Ù‚Ø©',
    'confirm': 'ØªØ£ÙƒÙŠØ¯', 'conflict': 'ØµØ±Ø§Ø¹', 'connect': 'Ø§Ù„Ø§ØªØµØ§Ù„', 'consider': 'Ø§Ù„Ù†Ø¸Ø± ÙÙŠ',
    'contain': 'ØªØ­ØªÙˆÙŠ', 'content': 'Ù…Ø­ØªÙˆÙ‰', 'context': 'Ø§Ù„Ø³ÙŠØ§Ù‚', 'control': 'Ø§Ù„ØªØ­ÙƒÙ…',
    'conversation': 'Ù…Ø­Ø§Ø¯Ø«Ø©', 'cook': 'Ø·Ù‡ÙŠ', 'cool': 'Ø¨Ø§Ø±Ø¯', 'copy': 'Ù†Ø³Ø®', 'core': 'Ø¬ÙˆÙ‡Ø±',
    'corn': 'Ø°Ø±Ø©', 'corner': 'Ø²Ø§ÙˆÙŠØ©', 'cost': 'ØªÙƒÙ„ÙØ©', 'country': 'Ø¯ÙˆÙ„Ø©', 'couple': 'Ø²ÙˆØ¬',
    'course': 'Ø¯ÙˆØ±Ø©', 'court': 'Ù…Ø­ÙƒÙ…Ø©', 'cousin': 'Ø§Ø¨Ù† Ø¹Ù…', 'cover': 'ØºØ·Ø§Ø¡', 'cow': 'Ø¨Ù‚Ø±Ø©',
    'create': 'Ø¥Ù†Ø´Ø§Ø¡', 'credit': 'Ø±ØµÙŠØ¯', 'crime': 'Ø¬Ø±ÙŠÙ…Ø©', 'crisis': 'Ø£Ø²Ù…Ø©', 'critical': 'Ø­Ø±Ø¬',
    'crop': 'Ù…Ø­ØµÙˆÙ„', 'cross': 'Ø¹Ø¨ÙˆØ±', 'crowd': 'Ø­Ø´Ø¯', 'crown': 'ØªØ§Ø¬', 'culture': 'Ø«Ù‚Ø§ÙØ©',
    'cup': 'ÙƒÙˆØ¨', 'current': 'Ø­Ø§Ù„ÙŠ', 'curve': 'Ù…Ù†Ø­Ù†Ù‰', 'custom': 'Ø¹Ø§Ø¯Ø©', 'cut': 'Ù‚Ø·Ø¹',
    'cute': 'Ø¬Ù…ÙŠÙ„', 'cycle': 'Ø¯ÙˆØ±Ø©', 'dad': 'Ø£Ø¨', 'daily': 'ÙŠÙˆÙ…ÙŠ', 'damage': 'Ø§Ù„Ø¶Ø±Ø±',
    'dance': 'Ø±Ù‚Øµ', 'danger': 'Ø®Ø·Ø±', 'dare': 'ØªØ¬Ø±Ø¤', 'dark': 'Ù…Ø¸Ù„Ù…', 'data': 'Ø¨ÙŠØ§Ù†Ø§Øª',
    'date': 'ØªØ§Ø±ÙŠØ®', 'daughter': 'Ø§Ø¨Ù†Ø©', 'day': 'ÙŠÙˆÙ…', 'dead': 'Ù…ÙŠØª', 'deal': 'ØµÙÙ‚Ø©',
    'dear': 'Ø¹Ø²ÙŠØ²', 'death': 'Ù…ÙˆØª', 'decide': 'Ù‚Ø±Ø±', 'decision': 'Ù‚Ø±Ø§Ø±', 'deck': 'Ø³Ø·Ø­ Ø§Ù„Ø³ÙÙŠÙ†Ø©',
    'deep': 'Ø¹Ù…ÙŠÙ‚', 'deer': 'ØºØ²Ø§Ù„', 'defend': 'Ø¯ÙØ§Ø¹', 'define': 'ØªØ¹Ø±ÙŠÙ', 'degree': 'Ø¯Ø±Ø¬Ø©',
    'delay': 'ØªØ£Ø®ÙŠØ±', 'delete': 'Ø­Ø°Ù', 'deliver': 'ØªØ³Ù„ÙŠÙ…', 'demand': 'Ø·Ù„Ø¨', 'deny': 'Ø¥Ù†ÙƒØ§Ø±',
    'depend': 'ÙŠØ¹ØªÙ…Ø¯', 'deposit': 'Ø¥ÙŠØ¯Ø§Ø¹', 'depth': 'Ø¹Ù…Ù‚', 'describe': 'ÙˆØµÙ', 'desert': 'ØµØ­Ø±Ø§Ø¡',
    'design': 'ØªØµÙ…ÙŠÙ…', 'desk': 'Ù…ÙƒØªØ¨', 'destroy': 'ØªØ¯Ù…ÙŠØ±', 'detail': 'ØªÙØµÙŠÙ„', 'detect': 'Ø§Ù„ÙƒØ´Ù',
    'determine': 'ØªØ­Ø¯ÙŠØ¯', 'develop': 'ØªØ·ÙˆØ±', 'device': 'Ø¬Ù‡Ø§Ø²', 'diamond': 'Ù…Ø§Ø³', 'die': 'Ù…ÙˆØª',
    'diet': 'Ù†Ø¸Ø§Ù… ØºØ°Ø§Ø¦ÙŠ', 'differ': 'ÙŠØ®ØªÙ„Ù', 'different': 'Ù…Ø®ØªÙ„Ù', 'difficult': 'ØµØ¹Ø¨', 'dig': 'Ø­ÙØ±',
    'dinner': 'Ø¹Ø´Ø§Ø¡', 'direct': 'Ù…Ø¨Ø§Ø´Ø±Ø©', 'direction': 'Ø§ØªØ¬Ø§Ù‡', 'director': 'Ù…Ø¯ÙŠØ±', 'dirty': 'Ù‚Ø°Ø±',
    'disease': 'Ù…Ø±Ø¶', 'display': 'Ø¹Ø±Ø¶', 'distance': 'Ù…Ø³Ø§ÙØ©', 'divide': 'ØªÙ‚Ø³ÙŠÙ…', 'do': 'Ø§ÙØ¹Ù„',
    'doctor': 'Ø·Ø¨ÙŠØ¨', 'document': 'ÙˆØ«ÙŠÙ‚Ø©', 'dog': 'ÙƒÙ„Ø¨', 'dollar': 'Ø¯ÙˆÙ„Ø§Ø±', 'door': 'Ø¨Ø§Ø¨',
    'double': 'Ù…Ø¶Ø§Ø¹Ù', 'doubt': 'Ø´Ùƒ', 'down': 'Ø£Ø³ÙÙ„', 'draft': 'Ù…Ø³ÙˆØ¯Ø©', 'drag': 'Ø³Ø­Ø¨',
    'drama': 'Ø¯Ø±Ø§Ù…Ø§', 'draw': 'Ø±Ø³Ù…', 'dream': 'Ø­Ù„Ù…', 'dress': 'ÙØ³ØªØ§Ù†', 'drink': 'Ø´Ø±Ø§Ø¨',
    'drive': 'Ù‚ÙŠØ§Ø¯Ø©', 'drop': 'Ù‚Ø·Ø±Ø©', 'drug': 'Ø¯ÙˆØ§Ø¡', 'drum': 'Ø·Ø¨Ù„', 'dry': 'Ø¬Ø§Ù',
    'due': 'ÙŠØ³ØªØ­Ù‚', 'dull': 'Ù…Ù…Ù„', 'dust': 'ØºØ¨Ø§Ø±', 'duty': 'ÙˆØ§Ø¬Ø¨', 'each': 'ÙƒÙ„',
    'eagle': 'Ù†Ø³Ø±', 'ear': 'Ø£Ø°Ù†', 'early': 'Ù…Ø¨ÙƒØ±Ø§', 'earn': 'Ø§ÙƒØªØ³Ø¨', 'earth': 'Ø£Ø±Ø¶',
    'ease': 'Ø³Ù‡ÙˆÙ„Ø©', 'easily': 'Ø¨Ø³Ù‡ÙˆÙ„Ø©', 'east': 'Ø´Ø±Ù‚', 'easy': 'Ø³Ù‡Ù„', 'eat': 'Ø£ÙƒÙ„',
    'education': 'ØªØ¹Ù„ÙŠÙ…', 'effect': 'ØªØ£Ø«ÙŠØ±', 'effort': 'Ø¬Ù‡Ø¯', 'egg': 'Ø¨ÙŠØ¶Ø©', 'eight': 'Ø«Ù…Ø§Ù†ÙŠØ©',
    'either': 'Ø£ÙŠ Ù…Ù†', 'election': 'Ø§Ù†ØªØ®Ø§Ø¨Ø§Øª', 'electricity': 'ÙƒÙ‡Ø±Ø¨Ø§Ø¡', 'element': 'Ø¹Ù†ØµØ±',
    'elephant': 'ÙÙŠÙ„', 'else': 'Ø¢Ø®Ø±', 'email': 'Ø¨Ø±ÙŠØ¯ Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ', 'emotion': 'Ø¹Ø§Ø·ÙØ©',
    'emphasis': 'ØªØ±ÙƒÙŠØ²', 'empire': 'Ø¥Ù…Ø¨Ø±Ø§Ø·ÙˆØ±ÙŠØ©', 'employee': 'Ù…ÙˆØ¸Ù', 'empty': 'ÙØ§Ø±Øº',
    'end': 'Ù†Ù‡Ø§ÙŠØ©', 'enemy': 'Ø¹Ø¯Ùˆ', 'energy': 'Ø·Ø§Ù‚Ø©', 'engine': 'Ù…Ø­Ø±Ùƒ', 'engineer': 'Ù…Ù‡Ù†Ø¯Ø³',
    'english': 'Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ', 'enjoy': 'Ø§Ø³ØªÙ…ØªØ§Ø¹', 'enough': 'ÙƒØ§ÙÙŠ', 'enter': 'Ø§Ù„Ø¯Ø®ÙˆÙ„',
    'enterprise': 'Ù…Ø´Ø±ÙˆØ¹', 'entire': 'ÙƒØ§Ù…Ù„', 'entry': 'Ø¯Ø®ÙˆÙ„', 'envelope': 'Ù…Ø¸Ø±ÙˆÙ',
    'environment': 'Ø¨ÙŠØ¦Ø©', 'equal': 'Ù…ØªØ³Ø§Ùˆ', 'equipment': 'Ù…Ø¹Ø¯Ø§Øª', 'era': 'Ø¹ØµØ±', 'error': 'Ø®Ø·Ø£',
    'escape': 'Ù‡Ø±ÙˆØ¨', 'especially': 'Ø®Ø§ØµØ©', 'essay': 'Ù…Ù‚Ø§Ù„Ø©', 'essential': 'Ø£Ø³Ø§Ø³ÙŠ',
    'establish': 'ØªØ£Ø³ÙŠØ³', 'estate': 'Ø¶ÙŠØ¹Ø©', 'estimate': 'ØªÙ‚Ø¯ÙŠØ±', 'ethnic': 'Ø¹Ø±Ù‚ÙŠ',
    'evaluate': 'ØªÙ‚ÙŠÙŠÙ…', 'even': 'Ø­ØªÙ‰', 'event': 'Ø­Ø¯Ø«', 'ever': 'Ø£Ø¨Ø¯Ø§', 'every': 'ÙƒÙ„',
    'evidence': 'Ø¯Ù„ÙŠÙ„', 'evil': 'Ø´Ø±', 'exam': 'Ø§Ù…ØªØ­Ø§Ù†', 'example': 'Ù…Ø«Ø§Ù„', 'exceed': 'ØªØ¬Ø§ÙˆØ²',
    'excellent': 'Ù…Ù…ØªØ§Ø²', 'except': 'Ø¨Ø§Ø³ØªØ«Ù†Ø§Ø¡', 'exchange': 'ØµØ±Ù', 'excited': 'Ù…ØªØ­Ù…Ø³',
    'excitement': 'Ø¥Ø«Ø§Ø±Ø©', 'exclusive': 'Ø­ØµØ±ÙŠ', 'excuse': 'Ø¹Ø°Ø±', 'execute': 'ØªÙ†ÙÙŠØ°',
    'exercise': 'ØªÙ…Ø±ÙŠÙ†', 'exhaust': 'Ø§Ø³ØªÙ†Ø²Ø§Ù', 'exhibit': 'Ù…Ø¹Ø±Ø¶', 'exist': 'Ù…ÙˆØ¬ÙˆØ¯',
    'existence': 'ÙˆØ¬ÙˆØ¯', 'exit': 'Ø®Ø±ÙˆØ¬', 'expand': 'ØªÙˆØ³ÙŠØ¹', 'expect': 'ØªÙˆÙ‚Ø¹', 'expensive': 'Ù…ÙƒÙ„Ù',
    'experience': 'ØªØ¬Ø±Ø¨Ø©', 'experiment': 'ØªØ¬Ø±Ø¨Ø©', 'expert': 'Ø®Ø¨ÙŠØ±', 'explain': 'Ø´Ø±Ø­',
    'expose': 'ÙƒØ´Ù', 'express': 'Ø§Ù„ØªØ¹Ø¨ÙŠØ±', 'extend': 'ØªÙ…Ø¯ÙŠØ¯', 'extensive': 'ÙˆØ§Ø³Ø¹',
    'external': 'Ø®Ø§Ø±Ø¬ÙŠ', 'extra': 'Ø¥Ø¶Ø§ÙÙŠ', 'extreme': 'Ù‚ØµÙˆÙ‰', 'eye': 'Ø¹ÙŠÙ†', 'fabric': 'Ù†Ø³ÙŠØ¬',
    'face': 'ÙˆØ¬Ù‡', 'facility': 'ØªØ³Ù‡ÙŠÙ„', 'fact': 'Ø­Ù‚ÙŠÙ‚Ø©', 'factor': 'Ø¹Ø§Ù…Ù„', 'factory': 'Ù…ØµÙ†Ø¹',
    'faculty': 'ÙƒÙ„ÙŠØ©', 'fade': 'ÙŠØªÙ„Ø§Ø´Ù‰', 'fail': 'ÙØ´Ù„', 'failure': 'ÙØ´Ù„', 'fair': 'Ø¹Ø§Ø¯Ù„',
    'fall': 'Ø³Ù‚ÙˆØ·', 'false': 'Ø®Ø§Ø·Ø¦', 'fame': 'Ø´Ù‡Ø±Ø©', 'family': 'Ø¹Ø§Ø¦Ù„Ø©', 'famous': 'Ù…Ø´Ù‡ÙˆØ±',
    'fan': 'Ù…Ø±ÙˆØ­Ø©', 'fantastic': 'Ø±Ø§Ø¦Ø¹', 'fantasy': 'Ø®ÙŠØ§Ù„', 'farm': 'Ù…Ø²Ø±Ø¹Ø©', 'farmer': 'Ù…Ø²Ø§Ø±Ø¹',
    'fashion': 'Ù…ÙˆØ¶Ø©', 'fast': 'Ø³Ø±ÙŠØ¹', 'fate': 'Ù…ØµÙŠØ±', 'father': 'Ø£Ø¨', 'fault': 'Ø®Ø·Ø£',
    'fear': 'Ø®ÙˆÙ', 'feature': 'Ù…ÙŠØ²Ø©', 'federal': 'ÙÙŠØ¯Ø±Ø§Ù„ÙŠ', 'fee': 'Ø±Ø³Ù…', 'feed': 'Ø¥Ø·Ø¹Ø§Ù…',
    'feel': 'Ø´Ø¹ÙˆØ±', 'feeling': 'Ø´Ø¹ÙˆØ±', 'fellow': 'Ø²Ù…ÙŠÙ„', 'female': 'Ø§Ù…Ø±Ø£Ø©', 'fence': 'Ø³ÙŠØ§Ø¬',
    'festival': 'Ù…Ù‡Ø±Ø¬Ø§Ù†', 'fever': 'Ø­Ù…Ù‰', 'few': 'Ù‚Ù„ÙŠÙ„', 'fiber': 'Ø£Ù„ÙŠØ§Ù', 'fiction': 'Ø®ÙŠØ§Ù„',
    'field': 'Ø­Ù‚Ù„', 'fierce': 'Ø´Ø±Ø³', 'fifteen': 'Ø®Ù…Ø³Ø© Ø¹Ø´Ø±', 'fifth': 'Ø®Ø§Ù…Ø³', 'fifty': 'Ø®Ù…Ø³ÙˆÙ†',
    'fight': 'Ù‚ØªØ§Ù„', 'figure': 'Ø´ÙƒÙ„', 'file': 'Ù…Ù„Ù', 'fill': 'Ù…Ù„Ø¡', 'film': 'ÙÙŠÙ„Ù…',
    'filter': 'Ù…Ø±Ø´Ø­', 'final': 'Ù†Ù‡Ø§Ø¦ÙŠ', 'finance': 'ØªÙ…ÙˆÙŠÙ„', 'find': 'ÙŠØ¬Ø¯', 'fine': 'Ø¬ÙŠØ¯',
    'finger': 'Ø¥ØµØ¨Ø¹', 'finish': 'Ù†Ù‡Ø§ÙŠØ©', 'fire': 'Ù†Ø§Ø±', 'firm': 'Ø«Ø§Ø¨Øª', 'first': 'Ø£ÙˆÙ„',
    'fish': 'Ø³Ù…Ùƒ', 'fit': 'Ù„Ø§Ø¦Ù‚', 'fitness': 'Ù„ÙŠØ§Ù‚Ø©', 'five': 'Ø®Ù…Ø³Ø©', 'fix': 'Ø¥ØµÙ„Ø§Ø­',
    'flag': 'Ø¹Ù„Ù…', 'flame': 'Ù„Ù‡Ø¨', 'flash': 'Ø¨Ø±Ù‚', 'flat': 'Ù…Ø³Ø·Ø­', 'flavor': 'Ù†ÙƒÙ‡Ø©',
    'flee': 'Ù‡Ø±ÙˆØ¨', 'flesh': 'Ù„Ø­Ù…', 'flight': 'Ø±Ø­Ù„Ø©', 'float': 'Ø·ÙÙˆ', 'flood': 'ÙÙŠØ¶Ø§Ù†',
    'floor': 'Ø£Ø±Ø¶ÙŠØ©', 'flower': 'Ø²Ù‡Ø±Ø©', 'fluid': 'Ø³Ø§Ø¦Ù„', 'fly': 'ÙŠØ·ÙŠØ±', 'focus': 'Ø§Ù„ØªØ±ÙƒÙŠØ²',
    'fold': 'Ø·ÙŠ', 'folk': 'Ø´Ø¹Ø¨', 'follow': 'Ù…ØªØ§Ø¨Ø¹Ø©', 'food': 'Ø·Ø¹Ø§Ù…', 'fool': 'Ø£Ø­Ù…Ù‚',
    'foot': 'Ù‚Ø¯Ù…', 'force': 'Ù‚ÙˆØ©', 'foreign': 'Ø£Ø¬Ù†Ø¨ÙŠ', 'forest': 'ØºØ§Ø¨Ø©', 'forget': 'Ù†Ø³ÙŠØ§Ù†',
    'fork': 'Ø´ÙˆÙƒØ©', 'form': 'Ø´ÙƒÙ„', 'formal': 'Ø±Ø³Ù…ÙŠ', 'format': 'ØµÙŠØºØ©', 'former': 'Ø§Ù„Ø³Ø§Ø¨Ù‚',
    'fortune': 'Ø«Ø±ÙˆØ©', 'forum': 'Ù…Ù†ØªØ¯Ù‰', 'forward': 'Ù„Ù„Ø£Ù…Ø§Ù…', 'fossil': 'Ø£Ø­ÙÙˆØ±Ø©', 'foster': 'ØªØ¹Ø²ÙŠØ²',
    'found': 'Ø£Ø³Ø³', 'foundation': 'Ù…Ø¤Ø³Ø³Ø©', 'fountain': 'Ù†Ø§ÙÙˆØ±Ø©', 'four': 'Ø£Ø±Ø¨Ø¹Ø©', 'fourth': 'Ø±Ø§Ø¨Ø¹',
    'fraction': 'ÙƒØ³Ø±', 'frame': 'Ø¥Ø·Ø§Ø±', 'framework': 'Ø¥Ø·Ø§Ø± Ø¹Ù…Ù„', 'france': 'ÙØ±Ù†Ø³Ø§', 'frank': 'ØµØ±ÙŠØ­',
    'fraud': 'Ø§Ø­ØªÙŠØ§Ù„', 'freedom': 'Ø­Ø±ÙŠØ©', 'freeze': 'ØªØ¬Ù…ÙŠØ¯', 'french': 'ÙØ±Ù†Ø³ÙŠ', 'frequency': 'ØªÙƒØ±Ø§Ø±',
    'fresh': 'Ø·Ø§Ø²Ø¬', 'friend': 'ØµØ¯ÙŠÙ‚', 'friendly': 'ÙˆØ¯ÙŠ', 'frontier': 'Ø­Ø¯ÙˆØ¯', 'frost': 'ØµÙ‚ÙŠØ¹',
    'frown': 'Ø¹Ø¨ÙˆØ³', 'frozen': 'Ù…Ø¬Ù…Ø¯', 'fruit': 'ÙØ§ÙƒÙ‡Ø©', 'fulfill': 'ØªØ­Ù‚ÙŠÙ‚', 'full': 'Ù…Ù…ØªÙ„Ø¦',
    'fully': 'ØªÙ…Ø§Ù…Ø§', 'fun': 'Ù…ØªØ¹Ø©', 'function': 'ÙˆØ¸ÙŠÙØ©', 'fund': 'ØµÙ†Ø¯ÙˆÙ‚', 'fundamental': 'Ø£Ø³Ø§Ø³ÙŠ',
    'funding': 'ØªÙ…ÙˆÙŠÙ„', 'funeral': 'Ø¬Ù†Ø§Ø²Ø©', 'funny': 'Ù…Ø¶Ø­Ùƒ', 'future': 'Ù…Ø³ØªÙ‚Ø¨Ù„',
}

# Group words by semantic categories
categories = {
    'technology': [],
    'science': [],
    'business': [],
    'health': [],
    'education': [],
    'sports': [],
    'arts': [],
    'nature': [],
    'people': [],
    'food': [],
    'travel': [],
    'government': [],
}

# Keywords for categorization
keywords_map = {
    'technology': ['computer', 'software', 'hard', 'tech', 'digital', 'code', 'program', 'network', 'internet', 'data', 'system', 'process', 'email', 'online', 'virus', 'file', 'device', 'server', 'database', 'web', 'app', 'net', 'cyber', 'cloud', 'ai', 'compute', 'robot', 'script', 'byte'],
    'science': ['science', 'physics', 'chemistry', 'biology', 'medicine', 'research', 'experiment', 'theory', 'atom', 'cell', 'energy', 'element', 'compound', 'hypothesis', 'test', 'lab', 'chemical', 'reaction', 'quantum', 'molecular', 'genetic', 'evolution', 'species', 'organism', 'matter', 'force'],
    'business': ['business', 'company', 'market', 'trade', 'commerce', 'economy', 'finance', 'profit', 'loss', 'customer', 'product', 'service', 'sales', 'price', 'contract', 'deal', 'invest', 'bank', 'money', 'account', 'payment', 'invoice', 'purchase', 'vendor', 'corporate', 'client', 'asset', 'revenue'],
    'health': ['health', 'medical', 'doctor', 'hospital', 'disease', 'medicine', 'treatment', 'patient', 'nurse', 'care', 'therapy', 'surgery', 'illness', 'pain', 'recovery', 'healthy', 'sick', 'body', 'diagnosis', 'symptom', 'clinic', 'health', 'dental', 'mental', 'vaccine', 'immune', 'physical', 'drug'],
    'education': ['education', 'school', 'student', 'teacher', 'learn', 'teach', 'study', 'class', 'exam', 'test', 'knowledge', 'book', 'subject', 'grade', 'university', 'college', 'course', 'lecture', 'academy', 'training', 'skill', 'seminar', 'workshop', 'tutor', 'pupil', 'curriculum'],
    'sports': ['sport', 'play', 'game', 'team', 'win', 'lose', 'player', 'coach', 'ball', 'match', 'competition', 'race', 'run', 'jump', 'exercise', 'athlete', 'fitness', 'training', 'score', 'goal', 'referee', 'tournament', 'league', 'championship', 'medal', 'olympic'],
    'arts': ['art', 'music', 'dance', 'song', 'paint', 'draw', 'sing', 'theater', 'drama', 'film', 'movie', 'show', 'performance', 'actor', 'artist', 'creative', 'craft', 'design', 'sculpture', 'gallery', 'museum', 'concert', 'opera', 'ballet', 'poetry', 'novel'],
    'nature': ['nature', 'tree', 'plant', 'animal', 'forest', 'mountain', 'river', 'lake', 'ocean', 'sea', 'sky', 'weather', 'rain', 'snow', 'wind', 'storm', 'sun', 'moon', 'star', 'bird', 'flower', 'leaf', 'rock', 'soil', 'climate', 'environmental'],
    'people': ['person', 'people', 'man', 'woman', 'child', 'baby', 'family', 'friend', 'brother', 'sister', 'father', 'mother', 'parent', 'relative', 'human', 'individual', 'male', 'female', 'boy', 'girl', 'son', 'daughter', 'wife', 'husband', 'couple', 'grandfather'],
    'food': ['food', 'eat', 'drink', 'meal', 'fruit', 'vegetable', 'meat', 'bread', 'rice', 'milk', 'cheese', 'cake', 'candy', 'sweet', 'taste', 'hungry', 'kitchen', 'cook', 'recipe', 'restaurant', 'dish', 'soup', 'salad', 'dessert', 'beverage', 'appetite', 'cuisine'],
    'travel': ['travel', 'trip', 'journey', 'visit', 'airport', 'train', 'plane', 'car', 'road', 'street', 'city', 'country', 'hotel', 'ticket', 'passport', 'luggage', 'tourist', 'map', 'route', 'destination', 'transport', 'vehicle', 'station', 'voyage', 'tour', 'cruise'],
    'government': ['government', 'political', 'politician', 'president', 'congress', 'senate', 'parliament', 'election', 'vote', 'law', 'legal', 'court', 'justice', 'crime', 'police', 'military', 'war', 'peace', 'nation', 'state', 'authority', 'regulation', 'treaty', 'diplomat', 'citizen', 'constitution'],
}

# Assign words to categories
remaining_words = set(all_words)
for word in sorted(all_words):
    word_lower = word.lower()
    assigned = False
    for category, keywords in keywords_map.items():
        if any(keyword in word_lower for keyword in keywords):
            categories[category].append(word)
            remaining_words.discard(word)
            assigned = True
            break

# Create JSON output
output = {}
for cat, words in categories.items():
    if words:
        output[cat] = {
            'title': f'ğŸ“š {cat.title()}',
            'words': [
                {
                    'en': word,
                    'ar': arabic_trans.get(word.lower(), word)
                }
                for word in sorted(set(words))[:150]  # Limit to 150 per category
            ]
        }

# Add remaining words
if remaining_words:
    output['other'] = {
        'title': 'ğŸ“ Miscellaneous',
        'words': [
            {
                'en': word,
                'ar': arabic_trans.get(word.lower(), word)
            }
            for word in sorted(remaining_words)[:200]  # Limit to 200
        ]
    }

# Save to file
with open('_categories_with_arabic.json', 'w', encoding='utf-8') as f:
    json.dump(output, f, ensure_ascii=False, indent=2)

# Print statistics
total_words = sum(len(cat['words']) for cat in output.values())
print(f"\nâœ… Expanded categories created successfully!")
print(f"ğŸ“Š Statistics:")
print(f"  â€¢ Total categories: {len(output)}")
print(f"  â€¢ Total words in database: {total_words}")
print(f"  â€¢ Words with translations: {sum(1 for cat in output.values() for w in cat['words'] if w['ar'] != w['en'])}")
print(f"\nğŸ“‹ Category breakdown:")
for name, data in sorted(output.items()):
    print(f"  â€¢ {name.capitalize()}: {len(data['words'])} words")
